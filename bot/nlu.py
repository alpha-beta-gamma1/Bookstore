from sentence_transformers import SentenceTransformer, util
import torch
import google.generativeai as genai
import json
import re

class NLU:
    def __init__(self):
        # --------- Load embedding model ----------
        self.embed_model = SentenceTransformer("bkai-foundation-models/vietnamese-bi-encoder")

        # Intent máº«u
        self.intent_samples = {
            "greeting": [
                "xin chÃ o", "chÃ o báº¡n", "hello", "hi", "alo shop",
                "Ãª báº¡n", "shop Æ¡i", "hÃ­", "báº¡n Æ¡i", "chÃ o buá»•i sÃ¡ng",
                "good morning", "good evening"
            ],
            "search_book": [
                "tÃ¬m sÃ¡ch", "cÃ³ sÃ¡ch khÃ´ng", "giÃ¡ sÃ¡ch", "thÃ´ng tin sÃ¡ch",
                "sÃ¡ch nÃ y bao nhiÃªu", "cho mÃ¬nh há»i sÃ¡ch", "tÃ¬m giÃºp quyá»ƒn sÃ¡ch",
                "cÃ³ bÃ¡n quyá»ƒn ... khÃ´ng", "mÃ¬nh muá»‘n há»i vá» sÃ¡ch",
                "sÃ¡ch tÃªn ... cÃ³ khÃ´ng", "mÃ¬nh cáº§n thÃ´ng tin sÃ¡ch"
            ],
            "order_book": [
                "muá»‘n mua sÃ¡ch", "Ä‘áº·t sÃ¡ch", "order sÃ¡ch", "cho tÃ´i mua",
                "mÃ¬nh muá»‘n Ä‘áº·t mua", "láº¥y cho mÃ¬nh quyá»ƒn nÃ y", "cho mÃ¬nh Ä‘áº·t",
                "ship sÃ¡ch nÃ y cho mÃ¬nh", "tÃ´i muá»‘n mua quyá»ƒn ...", "chá»‘t Ä‘Æ¡n giÃºp mÃ¬nh",
                "order quyá»ƒn ...", "Ä‘áº·t mua quyá»ƒn ...",
                "cÃ³", "ok", "chá»‘t", "á»«", "yes", "Ä‘á»“ng Ã½", "mÃ¬nh mua","1 cuá»‘n"," 5 ","tÃ´i tÃªn "
                ,"tÃ´i lÃ  ","tÃ´i á»Ÿ ","giao Ä‘áº¿n ","giao hÃ ng Ä‘áº¿n ","sá»‘ Ä‘iá»‡n thoáº¡i ","Ä‘á»‹a chá»‰ ","sá»‘ Ä‘t "
                ,"sÄ‘t "
            ],
            "list_books": [
                "danh sÃ¡ch sÃ¡ch", "cÃ³ nhá»¯ng sÃ¡ch gÃ¬", "xem sÃ¡ch",
                "shop cÃ³ sÃ¡ch nÃ o", "cÃ³ loáº¡i nÃ o", "show sÃ¡ch Ä‘i",
                "liá»‡t kÃª sÃ¡ch giÃºp mÃ¬nh", "cho mÃ¬nh danh má»¥c sÃ¡ch",
                "nhá»¯ng quyá»ƒn nÃ o cÃ³ á»Ÿ shop"
            ],
            "check_stock": [
                "cÃ²n hÃ ng", "cÃ²n bao nhiÃªu", "cÃ²n sÃ¡ch khÃ´ng",
                "háº¿t hÃ ng chÆ°a", "cÃ²n quyá»ƒn nÃ y khÃ´ng", "cÃ³ cÃ²n tá»“n khÃ´ng",
                "stock cÃ²n khÃ´ng", "cÃ²n máº¥y cuá»‘n", "cÃ²n bao nhiÃªu báº£n"
            ],
            "thanks": [
                "cáº£m Æ¡n", "thanks", "thank you", "cÃ¡m Æ¡n",
                "thx", "thanks shop", "ok cáº£m Æ¡n nhiá»u", "cáº£m Æ¡n báº¡n nhiá»u"
            ],
            "confirm_order": [
                "xÃ¡c nháº­n", "ok", "Ä‘á»“ng Ã½", "chá»‘t Ä‘Æ¡n", "ok chá»‘t", "ok mÃ¬nh láº¥y",
                "mua luÃ´n", "Ä‘áº·t luÃ´n", "Ä‘á»“ng Ã½ mua", "oke", "okie"
            ],

            "bye": [
                "táº¡m biá»‡t", "bye", "háº¹n gáº·p láº¡i",
                "see you", "goodbye", "cÃºt Ä‘Ã¢y", "gáº·p láº¡i sau",
                "bye shop", "ok mÃ¬nh Ä‘i Ä‘Ã¢y"
            ]
        }

        # Encode cÃ¡c vÃ­ dá»¥
        self.intent_embeddings = {
            intent: self.embed_model.encode(samples, convert_to_tensor=True)
            for intent, samples in self.intent_samples.items()
        }

        # --------- LLM Config (Gemini) ----------
        genai.configure(api_key="AIzaSyCJxQsH_U1-zVNLnm-CKdbaVvx8ZPGoYhg")  # Ä‘áº·t key tháº­t
        self.llm_model = genai.GenerativeModel('gemini-2.0-flash')

        self.entity_prompt = """
        Báº¡n lÃ  má»™t trá»£ lÃ½ phÃ¢n tÃ­ch ngÃ´n ngá»¯ tá»± nhiÃªn.    
        YÃªu cáº§u: TrÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ tá»« cÃ¢u sau:
        - "book_title": tÃªn sÃ¡ch
        - "quantity": sá»‘ lÆ°á»£ng
        - "customer_name": tÃªn khÃ¡ch hÃ ng
        - "phone": sá»‘ Ä‘iá»‡n thoáº¡i
        - "address": Ä‘á»‹a chá»‰

        Tráº£ vá» JSON duy nháº¥t theo format:
        {{
        "entities": {{
            "book_title": "...",
            "quantity": 2,
            "customer_name": "...",
            "phone": "...",
            "address": "..."
        }}
        }}

        CÃ¢u cáº§n phÃ¢n tÃ­ch: "{user_input}"
        """

    # ---------- Step 1: detect intent báº±ng embedding ----------
    def classify_intent(self, text: str, threshold: float = 0.15):
        user_emb = self.embed_model.encode(text, convert_to_tensor=True)
        best_intent, best_score = None, -1

        for intent, examples_emb in self.intent_embeddings.items():
            cos_scores = util.cos_sim(user_emb, examples_emb)
            max_score = torch.max(cos_scores).item()
            if max_score > best_score:
                best_intent, best_score = intent, max_score

        # ğŸ” Náº¿u score nhá» hÆ¡n threshold thÃ¬ gÃ¡n intent = "unknown"
        if best_score < threshold:
            return "unknown", best_score
        
        return best_intent, best_score


    # ---------- Step 2: extract entities báº±ng LLM ----------
    def extract_entities(self, text: str):
        prompt = self.entity_prompt.format(user_input=text)
        try:
            response = self.llm_model.generate_content(prompt)
            json_str = response.text.strip().strip('`').replace("json", "").strip()
            return json.loads(json_str).get("entities", {})
        except Exception as e:
            print("LLM parse error:", e)
            return {}

    # ---------- Step 3: hÃ m tá»•ng há»£p ----------
    def analyze(self, text: str):
        intent, score = self.classify_intent(text)
        entities = {}
        # chá»‰ trÃ­ch xuáº¥t entity khi intent cáº§n
        if intent in ["order_book", "search_book"]:
            entities = self.extract_entities(text)
        return {
            # "intent": intent,
            "confidence": score,
            "entities": entities
        }
    
    def extract_entities_with_fallback(self, text: str):
        """Extract entities vá»›i fallback regex cho cÃ¡c trÆ°á»ng há»£p Ä‘Æ¡n giáº£n"""
        # Gá»i LLM trÆ°á»›c
        entities = self.extract_entities(text)
        
        # Fallback cho phone náº¿u LLM khÃ´ng extract Ä‘Æ°á»£c
        if not entities.get('phone'):
            phone_match = re.search(r'\b0\d{9,10}\b', text)
            if phone_match:
                entities['phone'] = phone_match.group()
        
        # Fallback cho quantity
        if not entities.get('quantity'):
            qty_match = re.search(r'\b(\d+)\s*(?:cuá»‘n|quyá»ƒn|cÃ¡i|cá»¥c)\b', text, re.IGNORECASE)
            if qty_match:
                entities['quantity'] = int(qty_match.group(1))
        
        # Fallback cho customer_name (náº¿u message chá»‰ cÃ³ tÃªn)
        if not entities.get('customer_name') and len(text.strip().split()) <= 3:
            # Náº¿u message ngáº¯n vÃ  khÃ´ng chá»©a sá»‘, cÃ³ thá»ƒ lÃ  tÃªn
            if not re.search(r'\d', text) and len(text.strip()) >= 2:
                entities['customer_name'] = text.strip().title()
        
        return entities

# ---------------- DEMO -----------------
if __name__ == "__main__":
    nlu = NLU()
    while True:
        user_input = input("Báº¡n: ")
        if user_input.lower() in ["quit", "exit"]:
            break
        result = nlu.analyze(user_input)
        print("->", result)